{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f332df40-a2c1-4774-bf1a-08b760c9a67d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import RegexTokenizer, CountVectorizer, StopWordsRemover, HashingTF, IDF, ChiSqSelector\n",
    "from pyspark.ml.feature import Tokenizer, Normalizer, StringIndexer\n",
    "from pyspark.sql.functions import col, lower\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LinearSVC, OneVsRest\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "from pyspark.mllib.util import MLUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd200b63-8ca2-4222-817e-37d5ea6fa35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_dataset = \"/user/dic24_shared/amazon-reviews/full/reviews_devset.json\"\n",
    "full_dataset = \"/user/dic24_shared/amazon-reviews/full/reviewscombined.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "035eca20-70d1-4a8f-9a00-47ff9624a6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File read successfully.\n",
      "root\n",
      " |-- asin: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- helpful: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- overall: double (nullable = true)\n",
      " |-- reviewText: string (nullable = true)\n",
      " |-- reviewTime: string (nullable = true)\n",
      " |-- reviewerID: string (nullable = true)\n",
      " |-- reviewerName: string (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- unixReviewTime: long (nullable = true)\n",
      "\n",
      "+----------+--------------------+-------+-------+--------------------+-----------+--------------+--------------------+-------------------+--------------+\n",
      "|      asin|            category|helpful|overall|          reviewText| reviewTime|    reviewerID|        reviewerName|            summary|unixReviewTime|\n",
      "+----------+--------------------+-------+-------+--------------------+-----------+--------------+--------------------+-------------------+--------------+\n",
      "|0981850006|Patio_Lawn_and_Garde| [6, 7]|    5.0|This was a gift f...| 12 3, 2009|A2VNYWOPJ13AFP|Amazon Customer \"...|             Delish|    1259798400|\n",
      "|B00002N66D|Patio_Lawn_and_Garde| [1, 1]|    5.0|This is a very ni...| 12 3, 2012|A2E5XXXC07AGA7|               James|      Nice spreader|    1354492800|\n",
      "|B00002N67U|Patio_Lawn_and_Garde| [0, 1]|    1.0|The metal base wi...|08 13, 2008|A16PX63WZIEQ13|             Finaldx|Terrible spike base|    1218585600|\n",
      "|B00002N6AN|Patio_Lawn_and_Garde| [0, 0]|    4.0|For the most part...| 10 1, 2009|A2OSWM3522VARA|Wayne Allen \"Moto...|  gets the job done|    1254355200|\n",
      "|B00002N8K3|Patio_Lawn_and_Garde| [4, 5]|    1.0|This hose is supp...|07 13, 2013|A2SX9YPPGEUADI|HappyCamper \"Happ...|          The worst|    1373673600|\n",
      "+----------+--------------------+-------+-------+--------------------+-----------+--------------+--------------------+-------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Initialize Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Text_Classification\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "try:\n",
    "    df = spark.read.json(partial_dataset)\n",
    "    print(\"File read successfully.\")\n",
    "    \n",
    "    # Show the schema and some data\n",
    "    df.printSchema()\n",
    "    df.show(5)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c336398-2c4d-4622-a71f-c8693594b730",
   "metadata": {},
   "source": [
    "# Part 1: RDDs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8824c96-9b4e-4f26-9670-3a9ba0aaa784",
   "metadata": {},
   "source": [
    "# Part 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10c26a83-efb3-4811-9efb-5ede4f8209eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casefolding\n",
    "df = df.withColumn(\"reviewText\", lower(col(\"reviewText\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb22f5e2-c855-454c-acf1-49673b463608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сonverting category to numeric\n",
    "indexer = StringIndexer(inputCol=\"category\", outputCol=\"categoryIndex\")\n",
    "\n",
    "# Creating the pipeline:\n",
    "\n",
    "# 1. tokenization\n",
    "tokenizer = RegexTokenizer(inputCol=\"reviewText\", outputCol=\"words\", pattern=r'\\s+|\\t+|\\d+|[(){}.!?,;:+=-_\"\\`~#@&*%€$§\\\\/]+', gaps=True)\n",
    "\n",
    "# 3. Stopwords removal\n",
    "stopwords_remover = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol=\"filtered_words\")\n",
    "\n",
    "\n",
    "# 4. TF-IDF calculation with HashingTF\n",
    "hashingTF = HashingTF(inputCol=stopwords_remover.getOutputCol(), outputCol=\"rawFeatures\", numFeatures=20)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "\n",
    "# 5. Chi-square\n",
    "selector = ChiSqSelector(numTopFeatures=2000, featuresCol=idf.getOutputCol(),\n",
    "                         outputCol=\"selectedFeatures\", labelCol=indexer.getOutputCol())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41ba8cf-5ef3-4c40-be27-29e31d3bde95",
   "metadata": {},
   "source": [
    "# Part 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f299317-66ab-445e-b252-1fa1900bb0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Normalizing\n",
    "normalizer = Normalizer(inputCol=selector.getOutputCol(), outputCol=\"normFeatures\")\n",
    "\n",
    "# 7. Creating SVM classificator\n",
    "svm = LinearSVC(featuresCol=normalizer.getOutputCol(), labelCol=\"categoryIndex\")\n",
    "\n",
    "# 8. Using One-vs-Rest for multiclass classification\n",
    "ovr = OneVsRest(classifier=svm, labelCol=\"categoryIndex\")\n",
    "\n",
    "\n",
    "pipeline = Pipeline(stages=[indexer, tokenizer, stopwords_remover, hashingTF, idf, selector, normalizer, ovr])\n",
    "\n",
    "\n",
    "# Output of the result\n",
    "# terms = result.select(\"selectedFeatures\").collect()\n",
    "# with open(\"output_ds.txt\", \"w\") as f:\n",
    "#     for term in terms:\n",
    "#         f.write(f\"{term}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6189059-fdd8-4077-ae6b-30c7cfa737c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set count: 55401\n",
      "Test set count: 11621\n",
      "Validation set count: 11807\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data\n",
    "train_df, test_df, validation_df = df.randomSplit([0.7, 0.15, 0.15], seed=42)\n",
    "\n",
    "\n",
    "# Show the count of each set\n",
    "print(\"Training set count:\", train_df.count())\n",
    "print(\"Test set count:\", test_df.count())\n",
    "print(\"Validation set count:\", validation_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43315cfc-0489-4d98-9cdc-7c3eeba8c35b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training...\n"
     ]
    }
   ],
   "source": [
    "# Creating a grid of parameters\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(selector.numTopFeatures, [2000, 500])  # number of features selected\n",
    "             .addGrid(svm.regParam, [0.01, 0.1, 1.0])  # Regularization parameter\n",
    "             .addGrid(svm.maxIter, [10, 50])  # Maximum number of iterations\n",
    "             .addGrid(svm.standardization, [True, False]) # Standardization\n",
    "             .build())\n",
    "\n",
    "\n",
    "# Creating a Cross Validator for Grid search\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(labelCol=\"categoryIndex\", metricName=\"f1\"),\n",
    "                          numFolds=3)\n",
    "\n",
    "# Model training\n",
    "try:\n",
    "    print(\"Starting model training...\")\n",
    "    model = crossval.fit(train_df)\n",
    "    print(\"Model training completed.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during model training: {e}\")\n",
    "\n",
    "\n",
    "# Predictions on the test data\n",
    "try:\n",
    "    print(\"Making predictions...\")\n",
    "    predictions = model.transform(test_df)\n",
    "    print(\"Predictions made.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during predictions: {e}\")\n",
    "\n",
    "\n",
    "# Evaluating the model\n",
    "try:\n",
    "    print(\"Evaluating the model...\")\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"categoryIndex\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "    f1_score = evaluator.evaluate(predictions)\n",
    "    print(f\"F1 Score: {f1_score}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during evaluation: {e}\")\n",
    "\n",
    "\n",
    "# Stopping Spark\n",
    "print(\"Stopping Spark...\")\n",
    "spark.stop()\n",
    "print(\"Spark stopped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0adb6db-5ed5-4e76-91b8-1ca0d5060a9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (DIC24)",
   "language": "python",
   "name": "python3_dic24"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
